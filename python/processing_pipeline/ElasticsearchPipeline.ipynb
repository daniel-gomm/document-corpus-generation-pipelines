{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "existing-procedure",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Pipeline import Pipeline\n",
    "import Adapters\n",
    "import Processors\n",
    "import Sinks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "selected-drama",
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack_copy import ElasticsearchDocumentStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "indian-garage",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_store = ElasticsearchDocumentStore(host=\"aifb-ls3-vm1.aifb.kit.edu\", username=\"\", password=\"\", index=\"document\")\n",
    "e_adapt = Adapters.ElasticsearchAdapter(document_store, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "broke-arizona",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13107346"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(e_adapt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "coral-detection",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': 'Convolutional neural networks (CNNs) handle the case where filters extend\\nbeyond the image boundary using several heuristics, such as zero, repeat or\\nmean padding. These schemes are applied in an ad-hoc fashion and, being weakly\\nrelated to the image content and oblivious of the target task, result in low\\noutput quality at the boundary. In this paper, we propose a simple and\\neffective improvement that learns the boundary handling itself. At\\ntraining-time, the network is provided with a separate set of explicit boundary\\nfilters. At testing-time, we use these filters which have learned to\\nextrapolate features at the boundary in an optimal way for the specific task.', 'score': None, 'probability': None, 'question': None, 'meta': {'arixive-id': '1805.03106', 'mag_id': 2800494737, '_split_id': 0}, 'embedding': None, 'id': 'a6c7df79ab869093c11a40c0f4e2cc0e'},\n",
       " {'text': \"Our extensive evaluation, over a wide range of architectural changes\\n(variations of layers, feature channels, or both), shows how the explicit\\nfilters result in improved boundary handling. Consequently, we demonstrate an\\nimprovement of 5% to 20% across the board of typical CNN applications\\n(colorization, de-Bayering, optical flow, and disparity estimation). Introduction When performing convolutions on a finite domain, boundary rules are required as the kernel's support extends beyond the edge. For convolutional neural networks (CNNs), many discrete filter kernels “slide” over a 2D image and typically boundary rules including zero, reflect, mean, clamp are used to extrapolate values outside the image.\", 'score': None, 'probability': None, 'question': None, 'meta': {'arixive-id': '1805.03106', 'mag_id': 2800494737, '_split_id': 1}, 'embedding': None, 'id': 'f9f8142b4fbc486c25664857287ff9'},\n",
       " {'text': 'FIGURE  Considering a simple detection filter (Fig. REF a) applied to a diagonal feature (Fig. REF b), we see that no boundary rule is ever ideal: zero will create a black boundary halo (Fig. REF c), using the mean color will reduce but not remove the issue (Fig. REF d), reflect and clamp (Fig. REF e and REF f) will create different kinks in a diagonal edge where the ground-truth continuation would be straight. In Fig.', 'score': None, 'probability': None, 'question': None, 'meta': {'arixive-id': '1805.03106', 'mag_id': 2800494737, '_split_id': 2}, 'embedding': None, 'id': '6b1f5a4a2533d34bfef345ae2255efaf'},\n",
       " {'text': 'REF  we visualize this as the error between the ideal response and the response we would observe at a location if a feature was present. In practical feature channels, these will manifest as false positive and negative images. These deteriorate overall feature quality, not only on the boundary but also inside. Another, equally unsatisfying, solution is to execute the CNN only on a “valid” interior part of the input image (crop), or to execute it multiple times and merge the outcome slide.', 'score': None, 'probability': None, 'question': None, 'meta': {'arixive-id': '1805.03106', 'mag_id': 2800494737, '_split_id': 3}, 'embedding': None, 'id': '6a85caea3d614d619676d89465dc4544'},\n",
       " {'text': 'Working in lower or multiple resolutions, the problem is even stronger, as low-resolution images have a higher percentage of boundary pixels. In a typical modern encoder-decoder , all will eventually become boundary pixels at some step. Having a second thought on what a 2D image actually is, we see, that the ideal boundary rule would be the one that extends the content exactly to the values an image taken with a larger sensor would have contained. Such a rule appears elusively hard to come by as it relies on information not observed.', 'score': None, 'probability': None, 'question': None, 'meta': {'arixive-id': '1805.03106', 'mag_id': 2800494737, '_split_id': 4}, 'embedding': None, 'id': 'ff8e6f8340b3efccba9f711bf453a67c'}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e_adapt.generate_documents(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thirty-entity",
   "metadata": {},
   "outputs": [],
   "source": [
    "update_pipeline = Pipeline(e_adapt, batch_size=20, cpus=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "derived-relations",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
