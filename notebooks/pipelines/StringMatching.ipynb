{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71806309",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/envs/KD/lib/python3.7/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n",
      "06/30/2021 12:32:43 - INFO - farm.modeling.prediction_head -   Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .\n",
      "[nltk_data] Downloading package punkt to /home/daniel/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Pool, current_process, Queue, Manager\n",
    "from kdpipelines.Pipeline import Pipeline\n",
    "from kdpipelines import Adapters, Processors, Sinks\n",
    "from functools import partial\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fb47e303",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/30/2021 12:40:03 - INFO - elasticsearch -   HEAD http://aifb-ls3-vm1.aifb.kit.edu:9200/ [status:200 request:0.055s]\n",
      "06/30/2021 12:40:03 - INFO - elasticsearch -   HEAD http://aifb-ls3-vm1.aifb.kit.edu:9200/document [status:200 request:0.018s]\n",
      "06/30/2021 12:40:03 - INFO - elasticsearch -   GET http://aifb-ls3-vm1.aifb.kit.edu:9200/document [status:200 request:0.019s]\n",
      "06/30/2021 12:40:03 - INFO - elasticsearch -   PUT http://aifb-ls3-vm1.aifb.kit.edu:9200/document/_mapping [status:200 request:0.025s]\n",
      "06/30/2021 12:40:03 - INFO - elasticsearch -   HEAD http://aifb-ls3-vm1.aifb.kit.edu:9200/label [status:200 request:0.019s]\n",
      "06/30/2021 12:40:03 - INFO - elasticsearch -   POST http://aifb-ls3-vm1.aifb.kit.edu:9200/document/_count [status:200 request:0.030s]\n",
      "06/30/2021 12:40:04 - INFO - elasticsearch -   DELETE http://aifb-ls3-vm1.aifb.kit.edu:9200/_search/scroll [status:200 request:0.057s]\n"
     ]
    }
   ],
   "source": [
    "from haystack.document_store.elasticsearch import ElasticsearchDocumentStore\n",
    "document_store = ElasticsearchDocumentStore(host=\"aifb-ls3-vm1.aifb.kit.edu\", username=\"\", password=\"\", index=\"document\")\n",
    "e_adapt = Adapters.ElasticsearchAdapter(document_store, batch_size=1000, filters={\"_status\":[\"1\"]})\n",
    "update_pipeline = Pipeline(e_adapt, batch_size=100, cpus=10, max_runtime=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "096e3b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../data/pwc_metadata/datasets_preprocessed.json') as f:\n",
    "    datasets = json.load(f)\n",
    "update_pipeline.add_processor(Processors.StringMatchingProcessor(datasets, info_field_name='datasets', info_key='pwc_url'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8483bf72",
   "metadata": {},
   "outputs": [],
   "source": [
    "update_pipeline.add_processor(Processors.MetadataFieldAdder(\"_status\", 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9b926b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/30/2021 12:32:48 - INFO - elasticsearch -   HEAD http://localhost:9200/ [status:200 request:0.004s]\n",
      "06/30/2021 12:32:48 - INFO - elasticsearch -   HEAD http://localhost:9200/document [status:200 request:0.006s]\n",
      "06/30/2021 12:32:48 - INFO - elasticsearch -   GET http://localhost:9200/document [status:200 request:0.004s]\n",
      "06/30/2021 12:32:48 - INFO - elasticsearch -   PUT http://localhost:9200/document/_mapping [status:200 request:0.012s]\n",
      "06/30/2021 12:32:48 - INFO - elasticsearch -   HEAD http://localhost:9200/label [status:200 request:0.003s]\n"
     ]
    }
   ],
   "source": [
    "local_document_store = ElasticsearchDocumentStore(host=\"localhost\", username=\"\", password=\"\", index=\"document\", duplicate_documents='overwrite')\n",
    "update_pipeline.add_sink(Sinks.ElasticsearchSink(local_document_store))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "edca63ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(ElasticsearchAdapter) ---> *StringMatchingProcessor* ---> *MetadataFieldAdder*\n",
      "===> |_ElasticsearchSink_|\n"
     ]
    }
   ],
   "source": [
    "print(update_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af59a521",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/30/2021 12:32:55 - INFO - root -   Pipeline processing started. A total of 6183181 documents will be processed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batches (10 minibatches at once): [............................................................] 0/6184 Processed documents: 0 Output Documents: 0\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/30/2021 12:32:55 - INFO - elasticsearch -   POST http://aifb-ls3-vm1.aifb.kit.edu:9200/document/_search?scroll=1d&size=1000 [status:200 request:0.515s]\n",
      "06/30/2021 12:33:31 - INFO - elasticsearch -   POST http://localhost:9200/_bulk?refresh=wait_for [status:200 request:0.943s]\n",
      "06/30/2021 12:33:32 - INFO - elasticsearch -   POST http://localhost:9200/_bulk?refresh=wait_for [status:200 request:1.013s]\n",
      "06/30/2021 12:33:33 - INFO - elasticsearch -   POST http://localhost:9200/_bulk?refresh=wait_for [status:200 request:1.011s]\n",
      "06/30/2021 12:33:34 - INFO - elasticsearch -   POST http://localhost:9200/_bulk?refresh=wait_for [status:200 request:1.011s]\n",
      "06/30/2021 12:33:35 - INFO - elasticsearch -   POST http://localhost:9200/_bulk?refresh=wait_for [status:200 request:1.009s]\n",
      "06/30/2021 12:33:36 - INFO - elasticsearch -   POST http://localhost:9200/_bulk?refresh=wait_for [status:200 request:1.010s]\n",
      "06/30/2021 12:33:37 - INFO - elasticsearch -   POST http://localhost:9200/_bulk?refresh=wait_for [status:200 request:1.010s]\n",
      "06/30/2021 12:33:38 - INFO - elasticsearch -   POST http://localhost:9200/_bulk?refresh=wait_for [status:200 request:1.009s]\n",
      "06/30/2021 12:33:39 - INFO - elasticsearch -   POST http://localhost:9200/_bulk?refresh=wait_for [status:200 request:1.011s]\n",
      "06/30/2021 12:33:40 - INFO - elasticsearch -   POST http://localhost:9200/_bulk?refresh=wait_for [status:200 request:1.008s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batches (10 minibatches at once): [............................................................] 1/6184 Processed documents: 1000 Output Documents: 1000\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/30/2021 12:33:41 - INFO - elasticsearch -   POST http://aifb-ls3-vm1.aifb.kit.edu:9200/_search/scroll [status:200 request:0.504s]\n",
      "06/30/2021 12:34:16 - INFO - elasticsearch -   POST http://localhost:9200/_bulk?refresh=wait_for [status:200 request:0.216s]\n",
      "06/30/2021 12:34:17 - INFO - elasticsearch -   POST http://localhost:9200/_bulk?refresh=wait_for [status:200 request:1.007s]\n",
      "06/30/2021 12:34:18 - INFO - elasticsearch -   POST http://localhost:9200/_bulk?refresh=wait_for [status:200 request:1.005s]\n",
      "06/30/2021 12:34:19 - INFO - elasticsearch -   POST http://localhost:9200/_bulk?refresh=wait_for [status:200 request:1.006s]\n",
      "06/30/2021 12:34:21 - INFO - elasticsearch -   POST http://localhost:9200/_bulk?refresh=wait_for [status:200 request:1.006s]\n",
      "06/30/2021 12:34:22 - INFO - elasticsearch -   POST http://localhost:9200/_bulk?refresh=wait_for [status:200 request:1.008s]\n",
      "06/30/2021 12:34:23 - INFO - elasticsearch -   POST http://localhost:9200/_bulk?refresh=wait_for [status:200 request:1.006s]\n",
      "06/30/2021 12:34:24 - INFO - elasticsearch -   POST http://localhost:9200/_bulk?refresh=wait_for [status:200 request:1.008s]\n",
      "06/30/2021 12:34:25 - INFO - elasticsearch -   POST http://localhost:9200/_bulk?refresh=wait_for [status:200 request:1.004s]\n",
      "06/30/2021 12:34:26 - INFO - elasticsearch -   POST http://localhost:9200/_bulk?refresh=wait_for [status:200 request:1.007s]\n",
      "06/30/2021 12:34:26 - INFO - root -   Maximum processing time exceeded. Stopping the pipeline.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batches (10 minibatches at once): [############################################################] 6184/6184 Processed documents: 2000 Output Documents: 2000\n",
      "Processing Done!\r"
     ]
    }
   ],
   "source": [
    "update_pipeline.process()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "031a5858",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/30/2021 12:36:07 - INFO - elasticsearch -   POST http://localhost:9200/document/_count [status:200 request:0.005s]\n",
      "06/30/2021 12:36:07 - INFO - elasticsearch -   DELETE http://localhost:9200/_search/scroll [status:200 request:0.002s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "68"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adapt = Adapters.ElasticsearchAdapter(local_document_store, batch_size=1000, filters={\"has_datasets\":[\"true\"]})\n",
    "len(adapt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8eafe995",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/30/2021 12:36:12 - INFO - elasticsearch -   POST http://localhost:9200/document/_search?scroll=1d&size=1000 [status:200 request:0.039s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'text': 'While some studies emphasize the feasibility of using Wikipedia data to forecast influenza\\xa0, dengue\\xa0, zika\\xa0, and other diseases\\xa0, other research concludes behavioral heterogeneity on social platforms like Wikipedia cannot reliably beat canonical epidemiological forecasting methods\\xa0, . We emphasize the goal of our study is not to evaluate the effectiveness of Wikipedia data in supporting emergency management or forecasting coronavirus incidence. Instead, we expect that coronavirus-related activity on Wikipedia will mirror previous disease outbreaks in terms of spikes of information seeking and contributions from editors of medical topics.',\n",
       "  'score': None,\n",
       "  'probability': None,\n",
       "  'question': None,\n",
       "  'meta': {'arixive-id': '2006.08899',\n",
       "   'mag_id': 3035517000,\n",
       "   '_split_id': 14,\n",
       "   '_status': 1,\n",
       "   'datasets': '[{\"title\": \"dengue\", \"pwc_url\": \"https://paperswithcode.com/dataset/dengue\", \"span\": [93, 99]}]',\n",
       "   'has_datasets': 'true'},\n",
       "  'embedding': None,\n",
       "  'id': 'c465920a63f922f3de50c56e32e0b7e0'},\n",
       " {'text': 'TABLE TABLE SceneNet RGB-D As shown in Table REF and Figure REF Bayesian SSD is able to achieve greater precision and recall scores than the vanilla SSD. While the SSD with Entropy thresholding network has a higher precision for some low recall levels, overall, Bayesian SSD is also shown to outperform this approach. This suggests that Bayesian SSD produces a more reliable uncertainty estimate for object classification; as such, it is able to make more informed decisions to reject incorrect classifications.',\n",
       "  'score': None,\n",
       "  'probability': None,\n",
       "  'question': None,\n",
       "  'meta': {'arixive-id': '1710.06677',\n",
       "   'mag_id': 2767194911,\n",
       "   '_split_id': 34,\n",
       "   '_status': 1,\n",
       "   'datasets': '[{\"title\": \"scenenet\", \"pwc_url\": \"https://paperswithcode.com/dataset/scenenet\", \"span\": [12, 20]}, {\"title\": \"scenenet rgb-d\", \"pwc_url\": \"https://paperswithcode.com/dataset/scenenet-rgb-d\", \"span\": [12, 26]}]',\n",
       "   'has_datasets': 'true'},\n",
       "  'embedding': None,\n",
       "  'id': '73f3a157878648a73c51df7e3de377cb'},\n",
       " {'text': \"However, we may only have the utilities of the end users, but miss the ones by other stakeholders. We can produce utilities for other stakeholders by utilizing existing preferences. utilized the MovieLens data and simulate the utilities for other stakeholders such as movie suppliers based on the user's ratings. Similar operations can be applied to the multi-criteria rating data for the purpose of the multi-stakeholder recommendations.\",\n",
       "  'score': None,\n",
       "  'probability': None,\n",
       "  'question': None,\n",
       "  'meta': {'arixive-id': '1707.08913',\n",
       "   'mag_id': 2741984768,\n",
       "   '_split_id': 23,\n",
       "   '_status': 1,\n",
       "   'datasets': '[{\"title\": \"movielens\", \"pwc_url\": \"https://paperswithcode.com/dataset/movielens\", \"span\": [195, 204]}]',\n",
       "   'has_datasets': 'true'},\n",
       "  'embedding': None,\n",
       "  'id': '9d59d003ca808e6f629b94f56a0668e4'},\n",
       " {'text': 'Another example could be the information sharing at the social networks. The information that a student shares with his or her friends may be different from the ones that are shared with his or her instructors. Students may not share complaints about the teaching with their instructors. Therefore, it is necessary to take these relationships into consideration in the recommendation process. Available Data Sets The data sets used in the group recommendations can be reused in this case. For example, Masthoff\\xa0 simulated a data based on the MovieLens movie data set.',\n",
       "  'score': None,\n",
       "  'probability': None,\n",
       "  'question': None,\n",
       "  'meta': {'arixive-id': '1707.08913',\n",
       "   'mag_id': 2741984768,\n",
       "   '_split_id': 25,\n",
       "   '_status': 1,\n",
       "   'datasets': '[{\"title\": \"movielens\", \"pwc_url\": \"https://paperswithcode.com/dataset/movielens\", \"span\": [542, 551]}]',\n",
       "   'has_datasets': 'true'},\n",
       "  'embedding': None,\n",
       "  'id': '52bb7357e6ce4384406fd7cd4894af25'},\n",
       " {'text': 'Note that as the number of labeled examples increases, usefulness of unlabeled examples decreases. We will subsequently discuss and analyze the results of each dataset in details in the next subsections. TABLE TABLE Ionosphere Ionosphere is a real-world dataset of radar pulses passing through the ionosphere which were collected by a system in Goose Bay, Labrador. The targets were free electrons in the ionosphere. “Good” radar returns are those showing evidence of some type of structure in the ionosphere.',\n",
       "  'score': None,\n",
       "  'probability': None,\n",
       "  'question': None,\n",
       "  'meta': {'arixive-id': '0804.0924',\n",
       "   'mag_id': 126603929,\n",
       "   '_split_id': 47,\n",
       "   '_status': 1,\n",
       "   'datasets': '[{\"title\": \"ionosphere\", \"pwc_url\": \"https://paperswithcode.com/dataset/ionosphere\", \"span\": [216, 226]}, {\"title\": \"ionosphere\", \"pwc_url\": \"https://paperswithcode.com/dataset/ionosphere\", \"span\": [227, 237]}, {\"title\": \"ionosphere\", \"pwc_url\": \"https://paperswithcode.com/dataset/ionosphere\", \"span\": [298, 308]}, {\"title\": \"ionosphere\", \"pwc_url\": \"https://paperswithcode.com/dataset/ionosphere\", \"span\": [405, 415]}, {\"title\": \"ionosphere\", \"pwc_url\": \"https://paperswithcode.com/dataset/ionosphere\", \"span\": [498, 508]}]',\n",
       "   'has_datasets': 'true'},\n",
       "  'embedding': None,\n",
       "  'id': '4a1a953a2ab6a993ac3eedd59fa45353'}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adapt.generate_documents(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "08e59779",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "241500"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(e_adapt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "db793e71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/30/2021 12:40:25 - INFO - elasticsearch -   POST http://aifb-ls3-vm1.aifb.kit.edu:9200/document/_search?scroll=1d&size=1000 [status:200 request:0.382s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'text': 'These fine-grained results also provide users with a measure concerning the expected adoption rate of the simulated mobility initiative, so as to figure out beforehand if the initiative can potentially succeed or not. Technically, a Tangramob simulation requires four inputs: the urban road network of the area under study, a representative population of the area with the mobility agendas of people. the description of the mobility services already offered by the city: public transport timetable, etc.',\n",
       "  'score': None,\n",
       "  'probability': None,\n",
       "  'question': None,\n",
       "  'meta': {'arixive-id': '1805.10906',\n",
       "   'mag_id': 2803352990,\n",
       "   '_split_id': 15,\n",
       "   '_status': 1,\n",
       "   'Section': 'results'},\n",
       "  'embedding': None,\n",
       "  'id': '3f1f4fc1141c8c8f93d0b8ebc67578c2'},\n",
       " {'text': 'It is worth mentioning that the definition of an agent population is certainly the most complex and critical information to supply, in particular in relation to profiles, and details on daily travels. Obviously, the more the population is representative of the reality of interest the more the results of the simulation can be considered a good approximation. Strategies for the derivation of a population are out of scope for this paper, nevertheless different sources are available to define a representative synthetic population.',\n",
       "  'score': None,\n",
       "  'probability': None,\n",
       "  'question': None,\n",
       "  'meta': {'arixive-id': '1805.10906',\n",
       "   'mag_id': 2803352990,\n",
       "   '_split_id': 16,\n",
       "   '_status': 1,\n",
       "   'Section': 'results'},\n",
       "  'embedding': None,\n",
       "  'id': 'd4f14c75a8462e35195f9bfc1eac101c'},\n",
       " {'text': 'Relevant data can be certainly collected from periodic census or questionnaires distributed to a sample population. Particularly effective nowadays is Mobile Crowd Sensing (MCS) that uses mobile apps developed for large scale sensing, and involve the contribution from a crowd of people that behave as probes of the dynamics of the mobility in the city .',\n",
       "  'score': None,\n",
       "  'probability': None,\n",
       "  'question': None,\n",
       "  'meta': {'arixive-id': '1805.10906',\n",
       "   'mag_id': 2803352990,\n",
       "   '_split_id': 17,\n",
       "   '_status': 1,\n",
       "   'Section': 'related'},\n",
       "  'embedding': None,\n",
       "  'id': '48aa56be37702d5e356af36623d6fa7'},\n",
       " {'text': \"GPS data produced by the crowd are an excellent source of planning and transport information, and they are widely used in mobility project (e.g., the community based GPS navigator Waze (www.waze.com) that tracks users to understand roadway congestion). Activity recognition of travel demand models can also be derived using Input-Output Hidden Markov Models (IOHMMs) to infer travelers' activity patterns from call detail records as suggested in . Starting from the provided information, the execution of Tangramob can be thought of as performing a comparative experiment.\",\n",
       "  'score': None,\n",
       "  'probability': None,\n",
       "  'question': None,\n",
       "  'meta': {'arixive-id': '1805.10906',\n",
       "   'mag_id': 2803352990,\n",
       "   '_split_id': 18,\n",
       "   '_status': 1,\n",
       "   'Section': 'discussion'},\n",
       "  'embedding': None,\n",
       "  'id': '49806e93ea75fd0c24672e42cfb6f00'},\n",
       " {'text': '  In relation extraction, a key process is to obtain good detectors that find relevant sentences describing the target relation. To minimize the necessity of labeled data for refining detectors, previous work successfully made use of BabelNet, a semantic graph structure expressing relationships between synsets, as side information or prior knowledge. The goal of this paper is to enhance the use of graph structure in the framework of random walk with a few adjustable parameters. Actually, a straightforward application of random walk degrades the performance even after parameter optimization.',\n",
       "  'score': None,\n",
       "  'probability': None,\n",
       "  'question': None,\n",
       "  'meta': {'arixive-id': '1609.00626',\n",
       "   'mag_id': 2510213926,\n",
       "   '_split_id': 0,\n",
       "   '_status': 1,\n",
       "   'Section': 'intro'},\n",
       "  'embedding': None,\n",
       "  'id': '2899eeddd783fde9fa2c3d1d5fcf9565'}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e_adapt.generate_documents(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476e8d66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
