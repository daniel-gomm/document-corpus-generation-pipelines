{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "existing-procedure",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/kit/stud/ulvhi/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "2021-08-05 10:37:03.144107: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "import nltk\n",
    "\n",
    "nltk.download('punkt')\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "from transformers import BertTokenizer\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "from transformers import BertForSequenceClassification\n",
    "from transformers import BertModel, BertConfig\n",
    "import random\n",
    "import numpy as np\n",
    "import operator\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from transformers import BertForSequenceClassification, BertTokenizer, TextClassificationPipeline\n",
    "import json\n",
    "import glob\n",
    "import os\n",
    "import csv\n",
    "import threading\n",
    "import time\n",
    "import multiprocessing\n",
    "from multiprocessing import Process, Manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "selected-drama",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/kit/stud/ulvhi/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from Pipeline import Pipeline\n",
    "import Adapters\n",
    "import Processors\n",
    "import Sinks\n",
    "from imrad_classification import BERTClassificationHandler\n",
    "from imrad_classification import ClassificationHandler\n",
    "from haystack_copy import ElasticsearchDocumentStore\n",
    "from queue import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "indian-garage",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kit/stud/ulvhi/.local/lib/python3.8/site-packages/elasticsearch/connection/base.py:208: ElasticsearchWarning: Elasticsearch built-in security features are not enabled. Without authentication, your cluster could be accessible to anyone. See https://www.elastic.co/guide/en/elasticsearch/reference/7.13/security-minimal-setup.html to enable security.\n",
      "  warnings.warn(message, category=ElasticsearchWarning)\n"
     ]
    }
   ],
   "source": [
    "model_path='/pfs/data5/home/kit/stud/ulvhi/ML_Modells/UnpaywallFinetuned_SciBERT002_epoch_100words_batches5.model'\n",
    "document_store = ElasticsearchDocumentStore(host=\"aifb-ls3-vm1.aifb.kit.edu\", username=\"\", password=\"\", index=\"document\", duplicate_documents= 'overwrite') #update ElasticsearchSink documents = true\n",
    "e_adapt = Adapters.ElasticsearchAdapter(document_store, batch_size=10, filters={'_status':[\"1\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e4a43d5f-c82c-4f8f-b3e5-0cdcf87fbbbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6404824\n"
     ]
    }
   ],
   "source": [
    "model_path='/pfs/data5/home/kit/stud/ulvhi/ML_Modells/UnpaywallFinetuned_SciBERT002_epoch_100words_batches5.model'\n",
    "document_store = ElasticsearchDocumentStore(host=\"aifb-ls3-vm1.aifb.kit.edu\", username=\"\", password=\"\", index=\"document\", duplicate_documents= 'overwrite') #update ElasticsearchSink documents = true\n",
    "e_adapt = Adapters.ElasticsearchAdapter(document_store, batch_size=10, filters={'_status':[\"4\"]})\n",
    "print(len(e_adapt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "broke-arizona",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at allenai/scibert_scivocab_cased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(ElasticsearchAdapter) ---> *IMRaDClassification*\n",
      "===> |_ElasticsearchSink_|\n"
     ]
    }
   ],
   "source": [
    "update_pipeline = Pipeline(e_adapt, batch_size=100, cpus=1, max_runtime=12000)\n",
    "#lockArray definieren\n",
    "update_pipeline.add_processor(Processors.IMRaDClassification(model_path))\n",
    "update_pipeline.add_sink(Sinks.ElasticsearchSink(document_store))\n",
    "#update_pipeline.add_sink(Sinks.CSVMetadataSink(\"testcsv.csv\",[\"arixive-id\", \"_split_id\"])) #\n",
    "\n",
    "print(update_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "coral-detection",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15457"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(e_adapt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "thirty-entity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batches: [############################################################] 773/773 Processed documents: 77241 Output Documents: 77241\n",
      "Processing Done!\r"
     ]
    }
   ],
   "source": [
    "update_pipeline.process()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "derived-relations",
   "metadata": {},
   "outputs": [],
   "source": [
    "#start:12.13  6424681\n",
    "#5674181\n",
    "#sever start 19:35\n",
    "#241500 processed\n",
    "#start 19:40\n",
    "#ende 23:10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e574750f-020d-499b-bb28-a81eef2375bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "{'text': 'For example, the sparse approximations introduce FORMULA (FORMULA ) inducing variables FORMULA to distillate the latent function values FORMULA through prior or posterior approximation\\xa0, thus reducing the time complexity to FORMULA . Moreover, further complexity reduction can be achieved by exploiting the structured inducing points and the iterative methods through matrix-vector multiplies, see for example\\xa0, . In contrast to the global sparse approximation, the complexity of GP can also be reduced through distributed computation\\xa0, and local approximation\\xa0, .', 'score': None, 'probability': None, 'question': None, 'meta': {'arixive-id': '2005.08467', 'mag_id': 3024325720, '_split_id': 2, '_status': 3, 'Section': 'intro', 'datasets': [], 'has_datasets': 'false', 'methods': [], 'has_methods': 'false', 'title': 'Deep Latent-Variable Kernel Learning'}, 'embedding': None, 'id': 'e24203c2effb66a5cd08658d3a687ea8'}\n",
    "{'text': 'After collecting traffic stats for each pair of source and destination, they will be sorted in descending order for their total amounts of hops\\xa0(number of hops\\xa0FORMULA \\xa0number of flits) and CS paths will be formed from the top of this sorted list while conflicting CS connections are simply discarded. Since this algorithm prioritizes frequently used source and destination pairs as CS path candidates, it is able to find good combinations of CS paths for given traffic patterns.', 'score': None, 'probability': None, 'question': None, 'meta': {'arixive-id': '2005.08478', 'mag_id': 3025011640, '_split_id': 32, '_status': 3, 'Section': 'method', 'datasets': [], 'has_datasets': 'false', 'methods': [], 'has_methods': 'false', 'title': 'Energy-Efficient On-Chip Networks through Profiled Hybrid Switching'}, 'embedding': None, 'id': '94ccbf462451fd229a2c7afff05352ef'}\n",
    "{'text': 'Having computed all FORMULA node degrees to which it wants to connect, the new node then broadcasts a message with these degree values. Once the existing nodes in the network receive such a message, the nodes of the desired degrees respond to the new node to establish a connection to it. Then, the new node selects the first FORMULA of the nodes with desired degrees and connects to them.', 'score': None, 'probability': None, 'question': None, 'meta': {'arixive-id': '1303.6323', 'mag_id': 2011954835, '_split_id': 35, '_status': 3, 'Section': 'method', 'datasets': [], 'has_datasets': 'false', 'methods': [], 'has_methods': 'false', 'title': 'Constructing Limited Scale-Free Topologies Over Peer-to-Peer Networks'}, 'embedding': None, 'id': '109d6fcd626af42e9aaf37bded0ea7e0'}\n",
    "{'text': 'Essentially, FORMULA trades off tangential velocity and force; the smaller its value, the more tangential forces are penalized. This is a projection to circle problem and two cases can be identified. If the solution lies inside the cone, the problem is an unconstrained quadratic one, and the solution is FORMULA Otherwise, the solution lies on the boundary FORMULA where FORMULA . For FORMULA the solution approaches the frictionless case, while for FORMULA energy dissipation is increased.', 'score': None, 'probability': None, 'question': None, 'meta': {'arixive-id': '2007.11261', 'mag_id': 3044967063, '_split_id': 23, '_status': 3, 'Section': 'discussion', 'datasets': [], 'has_datasets': 'false', 'methods': [], 'has_methods': 'false', 'title': 'Contact-Implicit Trajectory Optimization using an Analytically Solvable\\n  Contact Model for Locomotion on Variable Ground'}, 'embedding': None, 'id': '8c7348b6e86afd8da429dc5938980bbd'}\n",
    "{'text': 'In this paper, we adopt a two-layered GCN\\xa0 where the first layer (denoted as FORMULA ) maps the raw node features FORMULA to the intermediate embedding space, and the second layer (denoted as FORMULA ) further maps the intermediate node embeddings FORMULA to the output space. FORMULA where FORMULA and FORMULA are task-dependent output function and loss function, respectively. Note that a node-anchor affinity matrix FORMULA serves as a weighted adjacency matrix of a bipartite graph FORMULA allowing only direct connections between nodes and anchors.', 'score': None, 'probability': None, 'question': None, 'meta': {'arixive-id': '2006.13009', 'mag_id': 3036106327, '_split_id': 22, '_status': 3, 'Section': 'method', 'datasets': [], 'has_datasets': 'false', 'methods': [], 'has_methods': 'false', 'title': 'Iterative Deep Graph Learning for Graph Neural Networks: Better and\\n  Robust Node Embeddings'}, 'embedding': None, 'id': '4d100e4ed690897704568cde63fbb3d9'}\n",
    "{'text': 'Our goal is to maximize the ELBO subject to some restrictions on FORMULA . Before describing the form we choose for FORMULA we first note that the second integral in equation REF is itself a lower bound on the marginal probability of the FORMULA th group of observations: FORMULA Thus, for any particular value of FORMULA we can maximize the global ELBO over FORMULA by minimizing the KL divergence between FORMULA and FORMULA . Algorithms Our algorithm for optimizing the ELBO from equation REF is summarized in algorithm REF .', 'score': None, 'probability': None, 'question': None, 'meta': {'arixive-id': '1404.4114', 'mag_id': 1795258949, '_split_id': 18, '_status': 3, 'Section': 'method', 'datasets': [], 'has_datasets': 'false', 'methods': [], 'has_methods': 'false', 'title': 'Structured Stochastic Variational Inference'}, 'embedding': None, 'id': '2a40b8acfada63a62f797af9fb1424a9'}\n",
    "len(e_adapt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d5c1b9-88d6-4099-928e-8e8da1820476",
   "metadata": {},
   "outputs": [],
   "source": [
    "jsonDocument={'text': 'The performance difference after the first seven queries is statistically significant with a FORMULA level, which goes to FORMULA after ten queries. Conclusions This paper introduces CLEO, a preference elicitation algorithm that, unlike existing approaches, handles preference elicitation tasks defined over hybrid domains and with uncertain human feedback. A combinatorial formulation of the unknown DM utility function is adopted. CLEO consists of an incremental procedure, iteratively optimizing the learned approximation of DM utility function to generate candidate solutions and refining the approximation based on the human feedback received.', 'score': None, 'probability': None, 'question': None, 'meta': {'arixive-id': '1508.04261', 'mag_id': 2206671546, '_status': 0, '_split_id': 115}, 'embedding': None, 'id': '1540cf135faebf5dae7806863bf4ec7a'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df4d976-650e-449b-bc67-dc637e26b8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path=\"\"\n",
    "model = BertForSequenceClassification.from_pretrained(\"allenai/scibert_scivocab_cased\", num_labels=5, output_attentions=False, output_hidden_states=False)\n",
    "model.load_state_dict(torch.load(model_path, map_location=torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')))        \n",
    "classificationPipeline = TextClassificationPipeline(model=model, tokenizer=BertTokenizer.from_pretrained('allenai/scibert_scivocab_cased'), device=0)\n",
    "\n",
    "        \n",
    "def evaluateIMRAD(document):\n",
    "    helperArray=document[\"text\"]\n",
    "    labelArray=classificationPipeline(helperArray)\n",
    "    for i in range (0, len(labelArray)):\n",
    "        label=labelArray[i][\"label\"]\n",
    "        if (label==\"LABEL_0\"):\n",
    "            label=\"intro\"\n",
    "                \n",
    "        if (label==\"LABEL_1\"):\n",
    "            label=\"related\"\n",
    "                \n",
    "        if (label==\"LABEL_2\"):\n",
    "            label=\"method\"\n",
    "                \n",
    "        if (label==\"LABEL_3\"):\n",
    "            label=\"results\"\n",
    "                \n",
    "        if (label==\"LABEL_4\"):\n",
    "            label=\"discussion\"\n",
    "\n",
    "            document[\"meta\"][\"Section\"]=label\n",
    "            document[\"meta\"][\"_status\"]=1\n",
    "            \n",
    "        return document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ccdcdd-eebf-4946-b7a9-257cfa537242",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(evaluateIMRAD(jsonDocument))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d176ac-bd6e-47ee-ac68-4b090a951b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    " if (selected_device==0):\n",
    "                labelArray=self._classificationPipeline0(document[\"text\"])\n",
    "                \n",
    "            elif (selected_device==1):\n",
    "                labelArray=self._classificationPipeline1(document[\"text\"])\n",
    "                \n",
    "            elif (selected_device==2):\n",
    "                labelArray=self._classificationPipeline2(document[\"text\"])\n",
    "\n",
    "            elif (selected_device==3):\n",
    "                labelArray=self._classificationPipeline3(document[\"text\"])\n",
    "                \n",
    "            label=labelArray[0][\"label\"]\n",
    "            if (label==\"LABEL_0\"):\n",
    "                label=\"intro\"\n",
    "                \n",
    "            if (label==\"LABEL_1\"):\n",
    "                label=\"related\"\n",
    "                \n",
    "            if (label==\"LABEL_2\"):\n",
    "                label=\"method\"\n",
    "                \n",
    "            if (label==\"LABEL_3\"):\n",
    "                label=\"results\"\n",
    "                \n",
    "            if (label==\"LABEL_4\"):\n",
    "                label=\"discussion\"\n",
    "\n",
    "            document[\"meta\"][\"Section\"]=label\n",
    "            #print(document[\"meta\"])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af73381c-0f67-4f5d-9e67-00ea085bcf99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567daf0e-65d5-42f2-a367-a87bbd31842e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d705c446-7a0c-498f-962b-60a2b60832ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65595959-2a45-4cd6-b73e-d9893f856422",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a1a9ea-2dad-4cd3-8d35-8c98726778a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e8c9dc-0835-4d9e-81a0-a6714ed08dce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6e6323-dff5-4a47-bcd2-7afa2abc06d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
